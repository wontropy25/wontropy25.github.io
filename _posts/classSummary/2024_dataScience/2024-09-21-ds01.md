---
title: "1. Data Mining Process"
date: 2024-09-21 00:01:00 +0900
categories: [학부 수업, (3-2) Data Science]
tags: [data science]     # TAG names should always be lowercase
math: true
mermaid: true
header-includes: 
  - \usepackage{tikz}
  - \usepackage{pgfplots}
---

### [1.1] Data Mining Processing
---
1. Define, understand purpose 
2. Obtain Data
  - 결과가 일반화될 수 있도록 다양한 데이터 입력을 샘플링해줘야 한다. 
  - ex) 과금 유저와 무과금 유저의 데이터 비율을 다르게 적용
3. Explore, Clean, Preprocess Data 
  - ex. 사람 몸무게가 500kg이 들어왔다면 정리해야함
4. **Reduce the Data**
  - 데이터 차원 축소: 연속적인 데이터들을 카테고리화 하는 것, 데이터 연산 (AND, OR) 등을 통해 새로운 변수 생성
5. **Specify Task**
  - 클러스터링을 할건지, 분류를 할건지 등등 
6. **Choose The Techniques**
  - 어떤 데이터 마이닝 기술을 쓸 것인가? 접근 방법에 관한 것
7. Iterative Implementation and Tuning
  - 유효한 데이터를 가지고 과정을 반복
8. Assess Results
  - 평가 데이터(Test Data set)는 훈련 때 사용하면 안됨! 
9. Deploy the Best model


#### Terminology
![ds1-3](assets/img/school_ds/ds1-3.png)

- Data Object: 릴레이션의 Row 속성으로, 데이터 객체 하나를 칭한다. 
- Attribute: 릴레이션의 Column 속성으로, 데이터 객체의 특성을 의미한다.
- Data Set: 데이터 객체들의 집합
- Explanatory attribute: 설명 속성으로, 입력 변수들의 속성을 의미한다. (=Independent variable, Predicator)
- Target attribute: 최종적으로 구하는 속성을 의미한다. (=Dependent variable)

### [1.2] Data Types
---

![ds1-1](assets/img/school_ds/ds1-1.png)

#### Categorical (Qualitative) Attribute
범주형 자료는 텍스트나 숫자 형태로 표시될 수 있다. 이때 숫자는 주민등록번호처럼 대수로서의 의미를 가지지 않기 때문에 대수연산이 불가능하다.

- **norminal** 명목형 자료: 순서가 없는 자료. ex) 남자, 여자 등
- **ordinal** 순위형 자료: 순서가 있는 자료. ex) low, mid, high
- **binary** 자료: Pass or Fail, Yes or No

#### Numerical (Quantitative) Attribute
대수적 성질을 가지고, 측정 단위가 존재할 수 있다.

- **discrete** 변수
- **continuous** 변수

#### Record (Table) Data
- Data Set은 레코드의 집합이고, 각 레코드는 고정된 attribute들을 가진다.

![ds1-2](assets/img/school_ds/ds1-2.png)

#### Graph Data
- **데이터 사이의 연관성을 쉽게 분석**할 수 있게 만들어준다.

1. 데이터 객체들 간의 관계를 나타내는 경우: 노드는 데이터 객체이고 링크가 각 관계에 해당한다. (ex. SNS 네트워크)
2. 데이터 자체가 그래프 형태인 경우: 벤젠 분자와 같이 그 구조 자체가 그래프일 수도 있다.

> **그래프 데이터와 테이블 데이터의 차이** <br/>
- 문서를 인용한 문서를 재귀적으로 탐색하고자 할 경우, 테이블 데이터는 조인을 많이 해야 하지만 그래프는 DFS, BFS 방식을 통해 손쉽게 탐색이 가능하다.
- 새로운 속성을 추가해야 하는 경우, 테이블 데이터는 테이블을 새로 정의해야 하는 반면 그래프는 단순히 노드를 추가해주는 방식으로 다룰 수 있다.
{: .prompt-tip}

#### Sequential Data
1. Sequential transaction data: 'A를 구매한 후 B를 구매했다'와 같이 시간순으로 일어난 일 (Symbolic한 데이터 시퀀스)
2. Time series data: 주식과 같이 수치적인 데이터가 연속적으로 움직이는 경향
3. Sequence data: A, T, G, C와 같이 연속적으로 구성된 데이터

#### 데이터의 특성
- Dimensionality: Column이 너무 많으면 차원의 저주에 빠져 패턴 학습이 어려워진다. 따라서 차원 축소를 자주 사용한다.
- Distribution: 이상적으로는 정규분포가 되길 원하지만, 실제 데이터 세트는 한쪽으로 치우치는 등 다른 분포를 지닌다.

### [1.3] Data Quality
---
실제 데이터들은 완벽하지 않고, Missing된 정보가 있거나 여러가지 요인에 의해 이상한 정보가 담겨 있을 수 있다. (ex. 키가 2m이고 몸무게가 2kg인 사람)
- Measurement and Data collection error: 데이터 수집 시 발생하는 오류. 결측치 등이 해당한다.
- Noise: 랜덤하게 발생하는 측정 오류. **제거하기가 어렵기 때문에 Robust한 알고리즘으로 데이터를 다뤄야 한다!** 

#### Bias-Variance Tradeoff
![ds1-4](assets/img/school_ds/ds1-4.png)

- Precision (정밀도, 분산에 반비례)
- Bias (편향)

1. 분산이 낮고 편향이 낮은 것이 가장 이상적인 형태이다.
2. **Overfitting**: 분산이 높고 편향이 낮은 것. 모델의 복잡도가 높아 학습 데이터에 대해 너무 학습이 잘되서 실제 데이터에 대해서는 오차가 크게 나타난다. (족보만 믿고 공부하다가 새로운 문제가 나왔을 때 풀지 못하는 것과 비슷하다.)
3. **Underfitting**: 분산이 낮고 편향이 높은 것. 모델이 너무 간소화되어 예측 결과가 잘 맞지 않고 다른 데이터를 넣어도 비슷하게 결과가 나온다. 

#### IQR, Outliers
- IQR: 데이터들이 주어졌을 때 $25%$에서 $75%$ 사이의 영역을 의미한다. (즉 4분위 값 중 1분위 ~ 3분위 사이)
- IQR의 1.5배를 넘어가는 영역을 Outlier로 구분한다.

#### Handling Missing Data
결측치가 적은 경우 nan, null 등으로 처리하거나 삭제할수도 있다. 또는 중위값이나 평균값 등으로 대체해서 넣어줄수도 있다.
```python
# nan 값으로 처리
missingRows = housing_df.sample(10).index
housing_df.loc[missingRows, 'BEDROOMS'] = np.nan
print('Number of rows with valid BEDROOMS values after setting to NAN: ', len(housing_df['BEDROOMS']))

# 결측치가 있는 행 삭제
reduced_df = housing_df.dropna()
print('Number of rows after removing rows with missing values: ', len(reduced_df))

# 중위값으로 대체
medianBedrooms = housing_df['BEDROOMS'].median()
housing_df.BEDROOMS = housing_df.BEDROOMS.fillna(value=medianBedrooms)
print('Number of rows with valid BEDROOMS values after filling NA values: ', len(housing_df['BEDROOMS']))
```

### [1.4] Data Preprocessing
---
작성 예정입니다.