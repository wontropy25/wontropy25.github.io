---
title:  "[DB] 3. Hashing"
date: 2024-06-26 12:00:00 +0900
categories: [학부 수업, (3-1) Database]
tags: [database]
math: true
---

### 3.1 Hashing

---

Bucket은 엔트리들이 들어가는 4KB 크기의 디스크 블록이다. Search key를 해시 함수에 넣으면 어느 버킷에 저장될지가 결정된다. 이때 Search Key가 달라도 같은 버킷에 들어갈 수 있고, 버킷 안에서 key들은 정렬되지 않는다. Hash index에서 버킷에는 레코드의 포인터를 저장한다.


### 3.2 Static Hashing

---

여러 개의 레코드가 하나의 Search key값을 가질 수도 있고, 해시 함수가 레코드를 분배 시 한쪽으로 몰려서 비대칭 구조로 인해 Bucket Overflow가 발생할 수 있다.

- **Closed hashing:** 버킷이 꽉 차면 Overflow Bucket을 연결리스트로 추가한다. (Overflow chaining)
- **Open hashing:** 버킷이 꽉 차면 Linear Probing을 통해 순차적으로 다른 빈 공간을 찾아서 넣는다. 한 번에 저장된 위치를 찾기는 힘들어서 Hashing의 장점이 사라지지만 모든 공간을 다 사용할 수 있다.

![Static Hashing](assets/img/school_db/6_statichashing.png)

Bucket의 수가 너무 적으면 성능이 저하되고, 너무 많으면 남는 공간이 낭비될 수 있다. 따라서 데이터가 예상 가능한 범위에 있지 않고 업데이트가 자주 발생할 경우 Static Hashing이 적합하지 않을 수 있다. 해결방법으로 주기적으로 해시 함수를 변경하는 Rehashing이 있지만, 아래에 나오는 Dynamic Hashing(Extendible, Linear) 기법이 더 좋다.


### 3.3 Extendible Hashing

---

- Bucket에 대한 pointer를 모은 Bucket Address Table이라는 디렉토리를 사용한다. 만약 공간이 부족하면 디렉토리를 2배로 늘려 버킷의 수도 2배 늘린다.
- Key의 prefix가 $i$비트라 하면 디렉토리의 크기는 $2^i$가 되고 DB의 크기에 따라 $i$값이 변한다. Bucket의 개수도 동적으로 변하지만 $2^i$개 미만이다.
- Direcotry를 표현하기 위한 최소 비트 수가 Global depth이고, 각 버킷별로 key값을 식별하기 위해 읽어야 하는 비트 수가 Local Depth이다. Bucket이 가득 차서 Bucket Split이 발생할 때 Global depth = Local Depth일 경우 Global depth를 1 증가시켜준 후 Split을 진행해야 한다.


### 3.4 Extendible Hashing - Bucket Split

---

디렉토리의 크기가 4이므로 Global depth는 2이다. 각 버킷별로도 Local Depth를 가진다.

- **Insert(1101):** Local depth가 1인 버킷이 가득 찼으므로 Bucket Split이 일어난다. 대상 Bucket이 **Global depth > Local depth** 조건을 만족하므로 단순히 Local depth를 1 증가시킨 버킷들로 Split하고, 디렉토리가 Split된 버킷들을 따로 가리키게 업데이트한다.

![Extendible Hashing - Bucket Split](assets/img/school_db/7-1_hash.png)

- **Insert(11101):** Local depth가 2인 버킷이 가득 찼으므로 Bucket Split이 일어난다. 대상 Bucket이 **Global depth = Local depth**이므로 먼저 **Directory Doubling**을 통해 Global depth를 1 증가시키고, 각각의 포인터들을 업데이트한다. 이제 대상 Bucket이 **Global depth > Local depth** 조건을 만족하므로 Local depth를 1 증가시킨 버킷들로 Split하고 디렉토리가 Split된 버킷들을 따로 가리키게 업데이트한다.

![Extendible Hashing - Directory Doubling](assets/img/school_db/7-2_hash.png)

파일이 증가해도 Hash의 성능이 저하되지 않고, 공간에 대한 오버헤드가 적은 편이다. 하지만 디렉토리의 크기 자체가 매우 커지면 메모리 크기보다 커질 수도 있다. 이 경우 디렉토리를 B+ Tree로 관리할 수도 있다.

### 3.5 Linear Hashing

---

디렉토리를 사용하지 않고 임시 오버플로우 버킷을 사용해 Round Robin 방식으로 overflow chain의 문제를 처리한다. 각 Level i에 대해 해시 함수 $h_0, h_1, h_2, ...$가 존재하고 $h_i(key) = h(key) \mod (2^iN)$이다. i가 증가할 때마다 아래에서부터 한 비트씩 증가한다. (N: 버킷의 크기, 아래 예시에서 N = 4)

- **Insert(101011):** Level 0(하위 2비트)부터 시작한다. 11이므로 4번째 버킷을 보는데 가득 차있기 때문에 Overflow Bucket을 Chain으로 만들어주고, **Next Pointer가 가리키는 버킷의 레벨이 1 증가되어 하위 3비트를 보는 h1으로 Split 된다!** (000, 100) 이후 Next Pointer는 다음 버킷을 가리킨다.
- **Insert(110):** Level 0(하위 2비트)부터 시작한다. 10이므로 3번째 버킷을 보는데 가득 차있기 때문에 위와 같이 h1으로 Split되고 Next Pointer가 옮겨진다.
- **Insert(1000001):** 이번에는 next가 Overflow Bucket을 가진 Bucket을 가리킨다. 그러면 임시 Overflow Bucket과 함께 Split이 이루어지고 이 임시 Overflow Bucket은 사라진다.
- **Find(00101):** 먼저 Level 0에서 하위 2비트를 보고 확인하려는데 Next 포인터가 이미 지난 상태이므로 Split된 상태다. 따라서 다음 레벨인 Level 1로 올라가서 찾아야 한다! 하위 3비트가 101이므로 101 버킷에는 5가 있으니 찾을 수 있다.
![Linear Hashing](assets/img/school_db/8-1_linearhash.png)





### 3.6 Ordered Indexing vs Hashing

---

- **Insert, Delete 연산이 많은 경우** Ordered indexing(B+ Tree)이 유리하다.
- **Hashing은 Point query에 유리하고, Ordered Indexing(B+ Tree)은 Range query에 유리하다.**
- 대부분의 데이터베이스 시스템은 디스크 기반 데이터에 대해 B-tree를 사용하고, 해시 인덱스는 주로 인메모리에서 사용된다.


### 3.7 Bitmap Indices

---

Gender와 같은 특징은 레코드별로 남자인 사람만 모은 10010 비트맵, 수입 레벨이 L1인 사람 10101처럼 간단히 나타낼 수 있다. 이 경우 AND 연산을 통해 조건을 모두 만족하는 레코드를 매우 빠르게 검색할 수 있다.


### 3.8 Query Cost

---

- **$t_T$:** Transfer Time / **$t_S$:** Seek time
- **$b_r \times t_T + S \times t_S$:** $b_r$개의 블록을 transfer 하고 $S$번 Seek 하는데 걸리는 시간
- 파일 블록이 연속적으로 저장되었다고 가정한 **Linear Search**의 cost: $b_r \times t_T + t_S$  
  - Unique key일 경우 평균적으로 $0.5b_r$개만 봐도 된다.
- 높이가 $h_i$인 B+ Tree index에서 **Point query**의 cost: $(h_i + 1) \times (t_T + t_S)$  
  - Root부터 트리 높이만큼 내려가면서 Transfer + Seek, 이후 leaf에서 마지막으로 Transfer + Seek 한 번 더 필요
- 높이가 $h_i$인 B+ Tree index에서 **Range query ($\sigma_{A \ge V}(r)$)**의 cost: $h_i \times (t_T + t_S) + t_S + b \times t_T$  
  - 먼저 V를 찾는 데 걸리는 시간 + V Seek + 연속적으로 b블록 이동하는 데 걸리는 시간



### 3.9 External Sort Merge

---

메모리 사이즈(페이지의 개수)가 M이라고 할 때, Runs라는 단위에 M 블록만큼 메모리로 읽어와서 총 N개의 Run을 만든다. 이후 각 블록 내에서 정렬을 하고 최종 output에 merge를 하는 방식이다.

- **N < M:** 바로 Merge Pass 한다.
- **N \ge M:** $M-1$개의 블록들끼리 모아서 Run을 또 만든 후에 Merge Pass를 진행한다. 아래 예시는 N=4, M=3이므로 2개의 블록끼리 모아서 Run을 한 번 더 만든 후에 Merge Pass를 진행했다.

![External Sort Merge](assets/img/school_db/9_externalSort.png)

- **Run의 개수:** $\lceil b_r / M \rceil$
- **Merge Pass의 횟수:** $\lceil \log_{M-1}(b_r/M) \rceil$
- **Total Transfer $t_T$:** $b_r \times (2\lceil \log_{M-1}(b_r/M) \rceil + 1)$
- **Run 생성 시 Seek:** 총 2번씩 일어난다.